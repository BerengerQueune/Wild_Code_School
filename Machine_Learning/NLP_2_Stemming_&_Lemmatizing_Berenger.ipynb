{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C1DWmq8Pm39",
        "outputId": "2accde2c-034a-46e6-b9c9-7f2d7f6637e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora\\words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     C:\\Users\\Berenger\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('popular')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from nltk.stem import SnowballStemmer\n",
        "stem_en = SnowballStemmer(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q_dOoVYZPxJB"
      },
      "outputs": [],
      "source": [
        "mytext = \"The Fermi paradox is a conflict between the argument that scale and probability seem to favor intelligent life being common in the universe, and the total lack of evidence of intelligent life having ever arisen anywhere other than on Earth. The first aspect of the Fermi paradox is a function of the scale or the large numbers involved: there are an estimated 200–400 billion stars in the Milky Way[25] (2–4 × 1011) and 70 sextillion (7×1022) in the observable universe.[26] Even if intelligent life occurs on only a minuscule percentage of planets around these stars, there might still be a great number of extant civilizations, and if the percentage were high enough it would produce a significant number of extant civilizations in the Milky Way. This assumes the mediocrity principle, by which Earth is a typical planet. The second aspect of the Fermi paradox is the argument of probability: given intelligent life's ability to overcome scarcity, and its tendency to colonize new habitats, it seems possible that at least some civilizations would be technologically advanced, seek out new resources in space, and colonize their own star system and, subsequently, surrounding star systems. Since there is no significant evidence on Earth, or elsewhere in the known universe, of other intelligent life after 13.8 billion years of the universe's history, there is a conflict requiring a resolution. Some examples of possible resolutions are that intelligent life is rarer than is thought, that assumptions about the general development or behavior of intelligent species are flawed, or, more radically, that current scientific understanding of the nature of the universe itself is quite incomplete. The Fermi paradox can be asked in two ways.[note 5] The first is, 'Why are no aliens or their artifacts found here on Earth, or in the Solar System?'. If interstellar travel is possible, even the 'slow' kind nearly within the reach of Earth technology, then it would only take from 5 million to 50 million years to colonize the galaxy.[27] This is relatively brief on a geological scale, let alone a cosmological one. Since there are many stars older than the Sun, and since intelligent life might have evolved earlier elsewhere, the question then becomes why the galaxy has not been colonized already. Even if colonization is impractical or undesirable to all alien civilizations, large-scale exploration of the galaxy could be possible by probes. These might leave detectable artifacts in the Solar System, such as old probes or evidence of mining activity, but none of these have been observed. The second form of the question is 'Why do we see no signs of intelligence elsewhere in the universe?'. This version does not assume interstellar travel, but includes other galaxies as well. For distant galaxies, travel times may well explain the lack of alien visits to Earth, but a sufficiently advanced civilization could potentially be observable over a significant fraction of the size of the observable universe.[28] Even if such civilizations are rare, the scale argument indicates they should exist somewhere at some point during the history of the universe, and since they could be detected from far away over a considerable period of time, many more potential sites for their origin are within range of human observation. It is unknown whether the paradox is stronger for the Milky Way galaxy or for the universe as a whole.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BPB_SdwcP1up"
      },
      "outputs": [],
      "source": [
        "tokens = nltk.word_tokenize(mytext.lower())\n",
        "\n",
        "tokens_clean = []\n",
        "for words in tokens:\n",
        "  if words not in nltk.corpus.stopwords.words(\"english\"):\n",
        "    tokens_clean.append(words)\n",
        "\n",
        "tokens_clean2 = []\n",
        "\n",
        "for i in range(len(tokens_clean)):\n",
        "  if tokens_clean[i] in \"!$%&'()*+, -./:;<=>?@[\\]^_`{|}~\":\n",
        "    pass\n",
        "  else:\n",
        "    tokens_clean2.append(tokens_clean[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "WYt5yfu1SnKH",
        "outputId": "78fb941d-5f24-4fb1-d6c5-3cb83af32b43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"fermi paradox conflict argument scale probability seem favor intelligent life common universe total lack evidence intelligent life ever arisen anywhere earth first aspect fermi paradox function scale large numbers involved estimated 200–400 billion stars milky way 25 2–4 × 1011 70 sextillion 7×1022 observable universe 26 even intelligent life occurs minuscule percentage planets around stars might still great number extant civilizations percentage high enough would produce significant number extant civilizations milky way assumes mediocrity principle earth typical planet second aspect fermi paradox argument probability given intelligent life 's ability overcome scarcity tendency colonize new habitats seems possible least civilizations would technologically advanced seek new resources space colonize star system subsequently surrounding star systems since significant evidence earth elsewhere known universe intelligent life 13.8 billion years universe 's history conflict requiring resolution examples possible resolutions intelligent life rarer thought assumptions general development behavior intelligent species flawed radically current scientific understanding nature universe quite incomplete fermi paradox asked two ways note 5 first 'why aliens artifacts found earth solar system interstellar travel possible even 'slow kind nearly within reach earth technology would take 5 million 50 million years colonize galaxy 27 relatively brief geological scale let alone cosmological one since many stars older sun since intelligent life might evolved earlier elsewhere question becomes galaxy colonized already even colonization impractical undesirable alien civilizations large-scale exploration galaxy could possible probes might leave detectable artifacts solar system old probes evidence mining activity none observed second form question 'why see signs intelligence elsewhere universe version assume interstellar travel includes galaxies well distant galaxies travel times may well explain lack alien visits earth sufficiently advanced civilization could potentially observable significant fraction size observable universe 28 even civilizations rare scale argument indicates exist somewhere point history universe since could detected far away considerable period time many potential sites origin within range human observation unknown whether paradox stronger milky way galaxy universe whole\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "string_clean =' '.join([str(item) for item in tokens_clean2])\n",
        "string_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttk2RA4aT2ga"
      },
      "source": [
        "From your already cleaned up text, so in lower case, without stopwords or punctuation, use a stemmer to make the corpus of words even more relevant, then use FreqDist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x83SvqQsPxCQ",
        "outputId": "9b3007a8-785e-44b6-e694-52bc3d7e05fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FreqDist({'intellig': 9, 'univers': 9, 'life': 7, 'earth': 6, 'civil': 6, 'galaxi': 6, 'paradox': 5, 'star': 5, 'observ': 5, 'colon': 5, ...})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_stem = [stem_en.stem(word) for word in nltk.word_tokenize(string_clean)]\n",
        "stem_freq = nltk.FreqDist(sent_stem)\n",
        "stem_freq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORZQlqgLd6XB"
      },
      "source": [
        "Did the stemmer bring up relevant information by grouping some words with the same root?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTKaxDrET_0e"
      },
      "source": [
        "<b><font color='orange'>I don't see anything particularly relevant yet.</font></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZgQdLC9USsc"
      },
      "source": [
        "From your already cleaned up text, therefore in lower case, without stopwords or punctuation, use a lemmatizer to make the corpus of words even more relevant, then use FreqDist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R-KPrPBP0oW",
        "outputId": "2a5422bd-fbd9-4e79-8791-b63adfd0f0fd"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21248/2014047166.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msent_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring_clean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlemma_lst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     )\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[index]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "sent_tokens = nlp(string_clean)\n",
        "\n",
        "lemma_lst = []\n",
        "\n",
        "for token in sent_tokens:\n",
        "  lemma_lst.append(token.lemma_)\n",
        "\n",
        "lemma_freq = nltk.FreqDist(lemma_lst)\n",
        "\n",
        "lemma_freq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oWbO-DXd9hs"
      },
      "source": [
        "Did the lemmatizer bring up relevant information by grouping some words with the same root?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOAvQBvUlvj"
      },
      "source": [
        "<b><font color='orange'>I don't see anything particularly relevant yet.</font></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b4nTsEUUops"
      },
      "source": [
        "Compare the two methods: are the words with the highest values in the FreqDist the same?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboTrC-FajjC",
        "outputId": "4079f846-07eb-4962-82b5-30cd5f558389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The five words with the most occurences by using stemming are: ['intellig', 'univers', 'life', 'earth', 'civil']\n",
            " \n",
            "The word with the most occurences is ('intellig', 9)\n",
            " \n",
            "The five words with the most occurences by using lemmatizing are: ['universe', 'intelligent', 'life', 'earth', 'civilization']\n",
            " \n",
            "The word with the most occurences is ('universe', 9)\n"
          ]
        }
      ],
      "source": [
        "print (f\"The five words with the most occurences by using stemming are: {sorted(stem_freq, key=stem_freq.get, reverse=True)[:5]}\")\n",
        "print (\" \")\n",
        "\n",
        "maximum = max(stem_freq, key=stem_freq.get)\n",
        "print(f\"The word with the most occurences is {maximum, stem_freq[maximum]}\")\n",
        "print (\" \")\n",
        "\n",
        "print (f\"The five words with the most occurences by using lemmatizing are: {sorted(lemma_freq, key=lemma_freq.get, reverse=True)[:5]}\")\n",
        "print (\" \")\n",
        "\n",
        "maximum = max(lemma_freq, key=lemma_freq.get)\n",
        "print(f\"The word with the most occurences is {maximum, lemma_freq[maximum]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msg4n8KtUsq8"
      },
      "source": [
        "<b><font color='orange'>- As we can see, the words with the highest occurences are not exactly the same.</font></b>\n",
        "\n",
        "<b><font color='orange'>- As a comparison measure I checked one word. The stemming returns 6 times the word \"galaxi\" while lemmatizing returns 6 times the word \"galaxy\". \"galaxy\" seems more relevant to me. so I prefer lemmatizing so far.</font></b>\n",
        "\n",
        "<b><font color='orange'>- Stemming returns 9 times \"intellig\" and \"univers\" while lemmatizin returns 8 times \"intelligent\", 1 time \"intelligence\" and 9 times \"universe\"</font></b>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\berenger\\anaconda3\\lib\\site-packages (21.0.1)Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: setuptools in c:\\users\\berenger\\anaconda3\\lib\\site-packages (58.0.4)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-59.4.0-py3-none-any.whl (952 kB)\n",
            "Requirement already satisfied: wheel in c:\\users\\berenger\\anaconda3\\lib\\site-packages (0.37.0)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 58.0.4\n",
            "    Uninstalling setuptools-58.0.4:\n",
            "      Successfully uninstalled setuptools-58.0.4\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.0.1\n",
            "    Uninstalling pip-21.0.1:\n",
            "      Successfully uninstalled pip-21.0.1\n",
            "Successfully installed pip-21.3.1 setuptools-59.4.0\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spyder 4.2.5 requires pyqt5<5.13, which is not installed.\n",
            "spyder 4.2.5 requires pyqtwebengine<5.13, which is not installed.\n",
            "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
            "anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n"
          ]
        }
      ],
      "source": [
        "pip install -U pip setuptools wheel"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NLP 2 - Stemming & Lemmatizing - Berenger.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
