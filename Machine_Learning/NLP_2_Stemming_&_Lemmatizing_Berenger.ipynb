{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP 2 - Stemming & Lemmatizing - Berenger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C1DWmq8Pm39",
        "outputId": "2accde2c-034a-46e6-b9c9-7f2d7f6637e3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('popular')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from nltk.stem import SnowballStemmer\n",
        "stem_en = SnowballStemmer(\"english\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_dOoVYZPxJB"
      },
      "source": [
        "mytext = \"The Fermi paradox is a conflict between the argument that scale and probability seem to favor intelligent life being common in the universe, and the total lack of evidence of intelligent life having ever arisen anywhere other than on Earth. The first aspect of the Fermi paradox is a function of the scale or the large numbers involved: there are an estimated 200–400 billion stars in the Milky Way[25] (2–4 × 1011) and 70 sextillion (7×1022) in the observable universe.[26] Even if intelligent life occurs on only a minuscule percentage of planets around these stars, there might still be a great number of extant civilizations, and if the percentage were high enough it would produce a significant number of extant civilizations in the Milky Way. This assumes the mediocrity principle, by which Earth is a typical planet. The second aspect of the Fermi paradox is the argument of probability: given intelligent life's ability to overcome scarcity, and its tendency to colonize new habitats, it seems possible that at least some civilizations would be technologically advanced, seek out new resources in space, and colonize their own star system and, subsequently, surrounding star systems. Since there is no significant evidence on Earth, or elsewhere in the known universe, of other intelligent life after 13.8 billion years of the universe's history, there is a conflict requiring a resolution. Some examples of possible resolutions are that intelligent life is rarer than is thought, that assumptions about the general development or behavior of intelligent species are flawed, or, more radically, that current scientific understanding of the nature of the universe itself is quite incomplete. The Fermi paradox can be asked in two ways.[note 5] The first is, 'Why are no aliens or their artifacts found here on Earth, or in the Solar System?'. If interstellar travel is possible, even the 'slow' kind nearly within the reach of Earth technology, then it would only take from 5 million to 50 million years to colonize the galaxy.[27] This is relatively brief on a geological scale, let alone a cosmological one. Since there are many stars older than the Sun, and since intelligent life might have evolved earlier elsewhere, the question then becomes why the galaxy has not been colonized already. Even if colonization is impractical or undesirable to all alien civilizations, large-scale exploration of the galaxy could be possible by probes. These might leave detectable artifacts in the Solar System, such as old probes or evidence of mining activity, but none of these have been observed. The second form of the question is 'Why do we see no signs of intelligence elsewhere in the universe?'. This version does not assume interstellar travel, but includes other galaxies as well. For distant galaxies, travel times may well explain the lack of alien visits to Earth, but a sufficiently advanced civilization could potentially be observable over a significant fraction of the size of the observable universe.[28] Even if such civilizations are rare, the scale argument indicates they should exist somewhere at some point during the history of the universe, and since they could be detected from far away over a considerable period of time, many more potential sites for their origin are within range of human observation. It is unknown whether the paradox is stronger for the Milky Way galaxy or for the universe as a whole.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPB_SdwcP1up"
      },
      "source": [
        "tokens = nltk.word_tokenize(mytext.lower())\n",
        "\n",
        "tokens_clean = []\n",
        "for words in tokens:\n",
        "  if words not in nltk.corpus.stopwords.words(\"english\"):\n",
        "    tokens_clean.append(words)\n",
        "\n",
        "tokens_clean2 = []\n",
        "\n",
        "for i in range(len(tokens_clean)):\n",
        "  if tokens_clean[i] in \"!$%&'()*+, -./:;<=>?@[\\]^_`{|}~\":\n",
        "    pass\n",
        "  else:\n",
        "    tokens_clean2.append(tokens_clean[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "WYt5yfu1SnKH",
        "outputId": "78fb941d-5f24-4fb1-d6c5-3cb83af32b43"
      },
      "source": [
        "string_clean =' '.join([str(item) for item in tokens_clean2])\n",
        "string_clean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"fermi paradox conflict argument scale probability seem favor intelligent life common universe total lack evidence intelligent life ever arisen anywhere earth first aspect fermi paradox function scale large numbers involved estimated 200–400 billion stars milky way 25 2–4 × 1011 70 sextillion 7×1022 observable universe 26 even intelligent life occurs minuscule percentage planets around stars might still great number extant civilizations percentage high enough would produce significant number extant civilizations milky way assumes mediocrity principle earth typical planet second aspect fermi paradox argument probability given intelligent life 's ability overcome scarcity tendency colonize new habitats seems possible least civilizations would technologically advanced seek new resources space colonize star system subsequently surrounding star systems since significant evidence earth elsewhere known universe intelligent life 13.8 billion years universe 's history conflict requiring resolution examples possible resolutions intelligent life rarer thought assumptions general development behavior intelligent species flawed radically current scientific understanding nature universe quite incomplete fermi paradox asked two ways note 5 first 'why aliens artifacts found earth solar system interstellar travel possible even 'slow kind nearly within reach earth technology would take 5 million 50 million years colonize galaxy 27 relatively brief geological scale let alone cosmological one since many stars older sun since intelligent life might evolved earlier elsewhere question becomes galaxy colonized already even colonization impractical undesirable alien civilizations large-scale exploration galaxy could possible probes might leave detectable artifacts solar system old probes evidence mining activity none observed second form question 'why see signs intelligence elsewhere universe version assume interstellar travel includes galaxies well distant galaxies travel times may well explain lack alien visits earth sufficiently advanced civilization could potentially observable significant fraction size observable universe 28 even civilizations rare scale argument indicates exist somewhere point history universe since could detected far away considerable period time many potential sites origin within range human observation unknown whether paradox stronger milky way galaxy universe whole\""
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttk2RA4aT2ga"
      },
      "source": [
        "From your already cleaned up text, so in lower case, without stopwords or punctuation, use a stemmer to make the corpus of words even more relevant, then use FreqDist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x83SvqQsPxCQ",
        "outputId": "9b3007a8-785e-44b6-e694-52bc3d7e05fa"
      },
      "source": [
        "sent_stem = [stem_en.stem(word) for word in nltk.word_tokenize(string_clean)]\n",
        "stem_freq = nltk.FreqDist(sent_stem)\n",
        "stem_freq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({\"'s\": 2,\n",
              "          '1011': 1,\n",
              "          '13.8': 1,\n",
              "          '200–400': 1,\n",
              "          '25': 1,\n",
              "          '26': 1,\n",
              "          '27': 1,\n",
              "          '28': 1,\n",
              "          '2–4': 1,\n",
              "          '5': 2,\n",
              "          '50': 1,\n",
              "          '70': 1,\n",
              "          '7×1022': 1,\n",
              "          'abil': 1,\n",
              "          'activ': 1,\n",
              "          'advanc': 2,\n",
              "          'alien': 3,\n",
              "          'alon': 1,\n",
              "          'alreadi': 1,\n",
              "          'anywher': 1,\n",
              "          'argument': 3,\n",
              "          'arisen': 1,\n",
              "          'around': 1,\n",
              "          'artifact': 2,\n",
              "          'ask': 1,\n",
              "          'aspect': 2,\n",
              "          'assum': 2,\n",
              "          'assumpt': 1,\n",
              "          'away': 1,\n",
              "          'becom': 1,\n",
              "          'behavior': 1,\n",
              "          'billion': 2,\n",
              "          'brief': 1,\n",
              "          'civil': 6,\n",
              "          'colon': 5,\n",
              "          'common': 1,\n",
              "          'conflict': 2,\n",
              "          'consider': 1,\n",
              "          'cosmolog': 1,\n",
              "          'could': 3,\n",
              "          'current': 1,\n",
              "          'detect': 2,\n",
              "          'develop': 1,\n",
              "          'distant': 1,\n",
              "          'earlier': 1,\n",
              "          'earth': 6,\n",
              "          'elsewher': 3,\n",
              "          'enough': 1,\n",
              "          'estim': 1,\n",
              "          'even': 4,\n",
              "          'ever': 1,\n",
              "          'evid': 3,\n",
              "          'evolv': 1,\n",
              "          'exampl': 1,\n",
              "          'exist': 1,\n",
              "          'explain': 1,\n",
              "          'explor': 1,\n",
              "          'extant': 2,\n",
              "          'far': 1,\n",
              "          'favor': 1,\n",
              "          'fermi': 4,\n",
              "          'first': 2,\n",
              "          'flaw': 1,\n",
              "          'form': 1,\n",
              "          'found': 1,\n",
              "          'fraction': 1,\n",
              "          'function': 1,\n",
              "          'galaxi': 6,\n",
              "          'general': 1,\n",
              "          'geolog': 1,\n",
              "          'given': 1,\n",
              "          'great': 1,\n",
              "          'habitat': 1,\n",
              "          'high': 1,\n",
              "          'histori': 2,\n",
              "          'human': 1,\n",
              "          'impract': 1,\n",
              "          'includ': 1,\n",
              "          'incomplet': 1,\n",
              "          'indic': 1,\n",
              "          'intellig': 9,\n",
              "          'interstellar': 2,\n",
              "          'involv': 1,\n",
              "          'kind': 1,\n",
              "          'known': 1,\n",
              "          'lack': 2,\n",
              "          'larg': 1,\n",
              "          'large-scal': 1,\n",
              "          'least': 1,\n",
              "          'leav': 1,\n",
              "          'let': 1,\n",
              "          'life': 7,\n",
              "          'mani': 2,\n",
              "          'may': 1,\n",
              "          'mediocr': 1,\n",
              "          'might': 3,\n",
              "          'milki': 3,\n",
              "          'million': 2,\n",
              "          'mine': 1,\n",
              "          'minuscul': 1,\n",
              "          'natur': 1,\n",
              "          'near': 1,\n",
              "          'new': 2,\n",
              "          'none': 1,\n",
              "          'note': 1,\n",
              "          'number': 3,\n",
              "          'observ': 5,\n",
              "          'occur': 1,\n",
              "          'old': 1,\n",
              "          'older': 1,\n",
              "          'one': 1,\n",
              "          'origin': 1,\n",
              "          'overcom': 1,\n",
              "          'paradox': 5,\n",
              "          'percentag': 2,\n",
              "          'period': 1,\n",
              "          'planet': 2,\n",
              "          'point': 1,\n",
              "          'possibl': 4,\n",
              "          'potenti': 2,\n",
              "          'principl': 1,\n",
              "          'probabl': 2,\n",
              "          'probe': 2,\n",
              "          'produc': 1,\n",
              "          'question': 2,\n",
              "          'quit': 1,\n",
              "          'radic': 1,\n",
              "          'rang': 1,\n",
              "          'rare': 1,\n",
              "          'rarer': 1,\n",
              "          'reach': 1,\n",
              "          'relat': 1,\n",
              "          'requir': 1,\n",
              "          'resolut': 2,\n",
              "          'resourc': 1,\n",
              "          'scale': 4,\n",
              "          'scarciti': 1,\n",
              "          'scientif': 1,\n",
              "          'second': 2,\n",
              "          'see': 1,\n",
              "          'seek': 1,\n",
              "          'seem': 2,\n",
              "          'sextillion': 1,\n",
              "          'sign': 1,\n",
              "          'signific': 3,\n",
              "          'sinc': 4,\n",
              "          'site': 1,\n",
              "          'size': 1,\n",
              "          'slow': 1,\n",
              "          'solar': 2,\n",
              "          'somewher': 1,\n",
              "          'space': 1,\n",
              "          'speci': 1,\n",
              "          'star': 5,\n",
              "          'still': 1,\n",
              "          'stronger': 1,\n",
              "          'subsequ': 1,\n",
              "          'suffici': 1,\n",
              "          'sun': 1,\n",
              "          'surround': 1,\n",
              "          'system': 4,\n",
              "          'take': 1,\n",
              "          'technolog': 2,\n",
              "          'tendenc': 1,\n",
              "          'thought': 1,\n",
              "          'time': 2,\n",
              "          'total': 1,\n",
              "          'travel': 3,\n",
              "          'two': 1,\n",
              "          'typic': 1,\n",
              "          'understand': 1,\n",
              "          'undesir': 1,\n",
              "          'univers': 9,\n",
              "          'unknown': 1,\n",
              "          'version': 1,\n",
              "          'visit': 1,\n",
              "          'way': 4,\n",
              "          'well': 2,\n",
              "          'whether': 1,\n",
              "          'whi': 2,\n",
              "          'whole': 1,\n",
              "          'within': 2,\n",
              "          'would': 3,\n",
              "          'year': 2,\n",
              "          '×': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORZQlqgLd6XB"
      },
      "source": [
        "Did the stemmer bring up relevant information by grouping some words with the same root?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTKaxDrET_0e"
      },
      "source": [
        "<b><font color='orange'>I don't see anything particularly relevant yet.</font></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZgQdLC9USsc"
      },
      "source": [
        "From your already cleaned up text, therefore in lower case, without stopwords or punctuation, use a lemmatizer to make the corpus of words even more relevant, then use FreqDist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R-KPrPBP0oW",
        "outputId": "2a5422bd-fbd9-4e79-8791-b63adfd0f0fd"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "sent_tokens = nlp(string_clean)\n",
        "\n",
        "lemma_lst = []\n",
        "\n",
        "for token in sent_tokens:\n",
        "  lemma_lst.append(token.lemma_)\n",
        "\n",
        "lemma_freq = nltk.FreqDist(lemma_lst)\n",
        "\n",
        "lemma_freq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({\"'\": 3,\n",
              "          \"'s\": 2,\n",
              "          '-': 1,\n",
              "          '1011': 1,\n",
              "          '13.8': 1,\n",
              "          '200–400': 1,\n",
              "          '25': 1,\n",
              "          '26': 1,\n",
              "          '27': 1,\n",
              "          '28': 1,\n",
              "          '2–4': 1,\n",
              "          '5': 2,\n",
              "          '50': 1,\n",
              "          '70': 1,\n",
              "          '7×1022': 1,\n",
              "          'ability': 1,\n",
              "          'activity': 1,\n",
              "          'advance': 1,\n",
              "          'advanced': 1,\n",
              "          'alien': 3,\n",
              "          'alone': 1,\n",
              "          'already': 1,\n",
              "          'anywhere': 1,\n",
              "          'argument': 3,\n",
              "          'arise': 1,\n",
              "          'around': 1,\n",
              "          'artifact': 2,\n",
              "          'ask': 1,\n",
              "          'aspect': 2,\n",
              "          'assume': 2,\n",
              "          'assumption': 1,\n",
              "          'away': 1,\n",
              "          'become': 1,\n",
              "          'behavior': 1,\n",
              "          'billion': 2,\n",
              "          'brief': 1,\n",
              "          'civilization': 6,\n",
              "          'colonization': 1,\n",
              "          'colonize': 4,\n",
              "          'common': 1,\n",
              "          'conflict': 2,\n",
              "          'considerable': 1,\n",
              "          'cosmological': 1,\n",
              "          'could': 3,\n",
              "          'current': 1,\n",
              "          'detect': 1,\n",
              "          'detectable': 1,\n",
              "          'development': 1,\n",
              "          'distant': 1,\n",
              "          'earlier': 1,\n",
              "          'earth': 6,\n",
              "          'elsewhere': 3,\n",
              "          'enough': 1,\n",
              "          'estimate': 1,\n",
              "          'even': 4,\n",
              "          'ever': 1,\n",
              "          'evidence': 3,\n",
              "          'evolve': 1,\n",
              "          'example': 1,\n",
              "          'exist': 1,\n",
              "          'explain': 1,\n",
              "          'exploration': 1,\n",
              "          'extant': 2,\n",
              "          'far': 1,\n",
              "          'favor': 1,\n",
              "          'fermi': 4,\n",
              "          'find': 1,\n",
              "          'first': 2,\n",
              "          'flaw': 1,\n",
              "          'form': 1,\n",
              "          'fraction': 1,\n",
              "          'function': 1,\n",
              "          'galaxy': 6,\n",
              "          'general': 1,\n",
              "          'geological': 1,\n",
              "          'give': 1,\n",
              "          'great': 1,\n",
              "          'habitat': 1,\n",
              "          'high': 1,\n",
              "          'history': 2,\n",
              "          'human': 1,\n",
              "          'impractical': 1,\n",
              "          'include': 1,\n",
              "          'incomplete': 1,\n",
              "          'indicate': 1,\n",
              "          'intelligence': 1,\n",
              "          'intelligent': 8,\n",
              "          'interstellar': 2,\n",
              "          'involve': 1,\n",
              "          'kind': 1,\n",
              "          'know': 1,\n",
              "          'lack': 2,\n",
              "          'large': 2,\n",
              "          'least': 1,\n",
              "          'leave': 1,\n",
              "          'let': 1,\n",
              "          'life': 7,\n",
              "          'many': 2,\n",
              "          'may': 4,\n",
              "          'mediocrity': 1,\n",
              "          'milky': 3,\n",
              "          'million': 2,\n",
              "          'mining': 1,\n",
              "          'minuscule': 1,\n",
              "          'nature': 1,\n",
              "          'nearly': 1,\n",
              "          'new': 2,\n",
              "          'none': 1,\n",
              "          'note': 1,\n",
              "          'number': 3,\n",
              "          'observable': 3,\n",
              "          'observation': 1,\n",
              "          'observe': 1,\n",
              "          'occur': 1,\n",
              "          'old': 2,\n",
              "          'one': 1,\n",
              "          'origin': 1,\n",
              "          'overcome': 1,\n",
              "          'paradox': 5,\n",
              "          'percentage': 2,\n",
              "          'period': 1,\n",
              "          'planet': 2,\n",
              "          'point': 1,\n",
              "          'possible': 4,\n",
              "          'potential': 1,\n",
              "          'potentially': 1,\n",
              "          'principle': 1,\n",
              "          'probability': 2,\n",
              "          'probe': 2,\n",
              "          'produce': 1,\n",
              "          'question': 2,\n",
              "          'quite': 1,\n",
              "          'radically': 1,\n",
              "          'range': 1,\n",
              "          'rare': 1,\n",
              "          'rarer': 1,\n",
              "          'reach': 1,\n",
              "          'relatively': 1,\n",
              "          'require': 1,\n",
              "          'resolution': 2,\n",
              "          'resource': 1,\n",
              "          'scale': 5,\n",
              "          'scarcity': 1,\n",
              "          'scientific': 1,\n",
              "          'second': 2,\n",
              "          'see': 1,\n",
              "          'seek': 1,\n",
              "          'seem': 2,\n",
              "          'sextillion': 1,\n",
              "          'sign': 1,\n",
              "          'significant': 3,\n",
              "          'since': 4,\n",
              "          'site': 1,\n",
              "          'size': 1,\n",
              "          'slow': 1,\n",
              "          'solar': 2,\n",
              "          'somewhere': 1,\n",
              "          'space': 1,\n",
              "          'specie': 1,\n",
              "          'star': 5,\n",
              "          'still': 1,\n",
              "          'strong': 1,\n",
              "          'subsequently': 1,\n",
              "          'sufficiently': 1,\n",
              "          'sun': 1,\n",
              "          'surround': 1,\n",
              "          'system': 4,\n",
              "          'take': 1,\n",
              "          'technologically': 1,\n",
              "          'technology': 1,\n",
              "          'tendency': 1,\n",
              "          'think': 1,\n",
              "          'time': 2,\n",
              "          'total': 1,\n",
              "          'travel': 3,\n",
              "          'two': 1,\n",
              "          'typical': 1,\n",
              "          'understanding': 1,\n",
              "          'undesirable': 1,\n",
              "          'universe': 9,\n",
              "          'unknown': 1,\n",
              "          'version': 1,\n",
              "          'visit': 1,\n",
              "          'way': 4,\n",
              "          'well': 2,\n",
              "          'whether': 1,\n",
              "          'whole': 1,\n",
              "          'why': 2,\n",
              "          'within': 2,\n",
              "          'would': 3,\n",
              "          'year': 2,\n",
              "          '×': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oWbO-DXd9hs"
      },
      "source": [
        "Did the lemmatizer bring up relevant information by grouping some words with the same root?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOAvQBvUlvj"
      },
      "source": [
        "<b><font color='orange'>I don't see anything particularly relevant yet.</font></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b4nTsEUUops"
      },
      "source": [
        "Compare the two methods: are the words with the highest values in the FreqDist the same?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboTrC-FajjC",
        "outputId": "4079f846-07eb-4962-82b5-30cd5f558389"
      },
      "source": [
        "print (f\"The five words with the most occurences by using stemming are: {sorted(stem_freq, key=stem_freq.get, reverse=True)[:5]}\")\n",
        "print (\" \")\n",
        "\n",
        "maximum = max(stem_freq, key=stem_freq.get)\n",
        "print(f\"The word with the most occurences is {maximum, stem_freq[maximum]}\")\n",
        "print (\" \")\n",
        "\n",
        "print (f\"The five words with the most occurences by using lemmatizing are: {sorted(lemma_freq, key=lemma_freq.get, reverse=True)[:5]}\")\n",
        "print (\" \")\n",
        "\n",
        "maximum = max(lemma_freq, key=lemma_freq.get)\n",
        "print(f\"The word with the most occurences is {maximum, lemma_freq[maximum]}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The five words with the most occurences by using stemming are: ['intellig', 'univers', 'life', 'earth', 'civil']\n",
            " \n",
            "The word with the most occurences is ('intellig', 9)\n",
            " \n",
            "The five words with the most occurences by using lemmatizing are: ['universe', 'intelligent', 'life', 'earth', 'civilization']\n",
            " \n",
            "The word with the most occurences is ('universe', 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msg4n8KtUsq8"
      },
      "source": [
        "<b><font color='orange'>- As we can see, the words with the highest occurences are not exactly the same.</font></b>\n",
        "\n",
        "<b><font color='orange'>- As a comparison measure I checked one word. The stemming returns 6 times the word \"galaxi\" while lemmatizing returns 6 times the word \"galaxy\". \"galaxy\" seems more relevant to me. so I prefer lemmatizing so far.</font></b>\n",
        "\n",
        "<b><font color='orange'>- Stemming returns 9 times \"intellig\" and \"univers\" while lemmatizin returns 8 times \"intelligent\", 1 time \"intelligence\" and 9 times \"universe\"</font></b>\n",
        "\n",
        "\n"
      ]
    }
  ]
}